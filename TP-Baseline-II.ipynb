{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 锂电池温度预测\n",
    "锂离子电池材料的主要生产设备是电炉，研究烧结过程的数字化建模，通过电炉空间温度推测产品内部温度，设计烧结过程的温度场和浓度场的最优控制律，搭建产品制备过程运行平台，有望最终实现该过程的效率提升和协同优化，达到提高产品一致性，降低生产能耗的目标。初赛提供了电炉17个温区的实际生产数据，分别是电炉上部17组加热棒设定温度T1-1~T1-17，电炉下部17组加热棒设定温度T2-1~T2-17，底部17组进气口的设定进气流量V1-V17，选手需要根据提供的数据样本构建模型，预测电炉上下部空间17个测温点的测量温度值。初赛考核办法采用测试集各行数据的加热棒上部温度设定值、加热棒下部温度设定值、进气流量3类数据作为输入，选手分别预测上部空间测量温度、下部空间测量温度。将选手预测的上部空间测量温度、下部空间测量温度与测试集数据的测量值进行比较。采用MAE平均绝对误差作为评价指标。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 环境配置"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "import optuna.visualization as ov\n",
    "from joblib import dump, load, Parallel, delayed\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !conda install pandas numpy sklearn lightgbm optuna joblib -y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 超参数配置"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 使用的特征\n",
    "USE_FEATURE_TYPES = ['timebase']\n",
    "USE_FEATURE_TYPES_ALL = ['timebase', 'time', 'statistical', 'overall', 'interaction', 'difference', 'ratio',\n",
    "                         'rolling_window',\n",
    "                         'spatial_gradient', 'time_gradient', 'time_spatial_gradient']\n",
    "# 模型训练迭代次数\n",
    "TRAIN_ROUND = 3\n",
    "\n",
    "# 超参数训练次数\n",
    "OPTUNA_ROUND = 50"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据准备"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 数据提取\n",
    "df_train = pd.read_csv(\"./datasets/train.csv\")\n",
    "df_test = pd.read_csv(\"./datasets/test.csv\")\n",
    "\n",
    "# 重命名\n",
    "df_train.columns = (\n",
    "        ['index', 'datetime'] +\n",
    "        [f'V{i + 1}' for i in range(17)] + [f'T1-{i + 1}' for i in range(17)] + [f'T2-{i + 1}' for i in range(17)] +\n",
    "        [f'T1R-{i + 1}' for i in range(17)] + [f'T2R-{i + 1}' for i in range(17)]\n",
    "\n",
    ")\n",
    "df_test.columns = df_train.columns[:53]\n",
    "df_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 特征工程"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_features(df, feature_types: [str, ...]):\n",
    "    df['timestamp'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values('timestamp')\n",
    "\n",
    "    # 时间特征-baseline\n",
    "    if 'timebase' in feature_types:\n",
    "        df['month'] = df['timestamp'].dt.month\n",
    "        df['day'] = df['timestamp'].dt.day\n",
    "        df['hour'] = df['timestamp'].dt.hour\n",
    "        df['minute'] = df['timestamp'].dt.minute\n",
    "        df['dayofweek'] = df['timestamp'].dt.dayofweek\n",
    "        df[\"dayofyear\"] = df[\"timestamp\"].dt.dayofyear\n",
    "        df[\"is_weekend\"] = df[\"timestamp\"].dt.dayofweek // 6\n",
    "        df[\"weekofyear\"] = df[\"时间\"].dt.isocalendar().week.astype(int)\n",
    "\n",
    "    # 时间特征\n",
    "    if 'time' in feature_types:\n",
    "        df['year'] = df['timestamp'].dt.year\n",
    "        df['month'] = df['timestamp'].dt.month\n",
    "        df['day'] = df['timestamp'].dt.day\n",
    "        df['hour'] = df['timestamp'].dt.hour\n",
    "        df['minute'] = df['timestamp'].dt.minute\n",
    "        df['dayofweek'] = df['timestamp'].dt.dayofweek\n",
    "\n",
    "    # 累积统计特征\n",
    "    if 'statistical' in feature_types:\n",
    "        for i in range(1, 18):\n",
    "            df[f'T1-{i}_mean'] = df[[f'T1-{j}' for j in range(1, i + 1)]].mean(axis=1)\n",
    "            df[f'T1-{i}_std'] = df[[f'T1-{j}' for j in range(1, i + 1)]].std(axis=1)\n",
    "\n",
    "            df[f'T2-{i}_mean'] = df[[f'T2-{j}' for j in range(1, i + 1)]].mean(axis=1)\n",
    "            df[f'T2-{i}_std'] = df[[f'T2-{j}' for j in range(1, i + 1)]].std(axis=1)\n",
    "\n",
    "            df[f'V{i}_mean'] = df[[f'V{j}' for j in range(1, i + 1)]].mean(axis=1)\n",
    "            df[f'V{i}_std'] = df[[f'V{j}' for j in range(1, i + 1)]].std(axis=1)\n",
    "\n",
    "    # 上下温度区总体特征\n",
    "    if 'overall' in feature_types:\n",
    "        # Average, min, max, and standard deviation\n",
    "        df['T1_mean'] = df[[f'T1-{i}' for i in range(1, 18)]].mean(axis=1)\n",
    "        df['T1_min'] = df[[f'T1-{i}' for i in range(1, 18)]].min(axis=1)\n",
    "        df['T1_max'] = df[[f'T1-{i}' for i in range(1, 18)]].max(axis=1)\n",
    "        df['T1_std'] = df[[f'T1-{i}' for i in range(1, 18)]].std(axis=1)\n",
    "\n",
    "        df['T2_mean'] = df[[f'T2-{i}' for i in range(1, 18)]].mean(axis=1)\n",
    "        df['T2_min'] = df[[f'T2-{i}' for i in range(1, 18)]].min(axis=1)\n",
    "        df['T2_max'] = df[[f'T2-{i}' for i in range(1, 18)]].max(axis=1)\n",
    "        df['T2_std'] = df[[f'T2-{i}' for i in range(1, 18)]].std(axis=1)\n",
    "\n",
    "        # Difference and ratio between upper and lower heating rods\n",
    "        df['T1_T2_diff'] = df['T1_mean'] - df['T2_mean']\n",
    "        df['T1_T2_ratio'] = df['T1_mean'] / df['T2_mean']\n",
    "\n",
    "    # 上下温度区交互特征\n",
    "    if 'interaction' in feature_types:\n",
    "        for i in range(1, 18):\n",
    "            df[f'T1-{i}_T2-{i}_diff'] = df[f'T1-{i}'] - df[f'T2-{i}']\n",
    "            df[f'T1-{i}_T2-{i}_ratio'] = df[f'T1-{i}'] / df[f'T2-{i}']\n",
    "            df[f'T1-{i}_T2-{i}_interaction'] = df[f'T1-{i}'] * df[f'T2-{i}']\n",
    "\n",
    "    # 相邻数据点的差值\n",
    "    if 'difference' in feature_types:\n",
    "        for i in range(1, 17):\n",
    "            df[f'T1-{i}_T1-{i + 1}_diff'] = df[f'T1-{i}'] - df[f'T1-{i + 1}']\n",
    "            df[f'T2-{i}_T2-{i + 1}_diff'] = df[f'T2-{i}'] - df[f'T2-{i + 1}']\n",
    "            df[f'V{i}_V{i + 1}_diff'] = df[f'V{i}'] - df[f'V{i + 1}']\n",
    "\n",
    "    # 比例特征\n",
    "    if 'ratio' in feature_types:\n",
    "        for i in range(1, 18):\n",
    "            df[f'T1-{i}_V{i}_ratio'] = df[f'T1-{i}'] / df[f'V{i}']\n",
    "            df[f'T2-{i}_V{i}_ratio'] = df[f'T2-{i}'] / df[f'V{i}']\n",
    "            df[f'T1-{i}_V{i}_interaction'] = df[f'T1-{i}'] * df[f'V{i}']\n",
    "            df[f'T2-{i}_V{i}_interaction'] = df[f'T2-{i}'] * df[f'V{i}']\n",
    "\n",
    "    # 滑动窗口特征\n",
    "    if 'rolling_window' in feature_types:\n",
    "        window_sizes = [i for i in range(1, 5)]  # Change this list according to your needs\n",
    "        for window_size in window_sizes:\n",
    "            for i in range(1, 18):\n",
    "                df[f'T1-{i}_rolling_mean_{window_size}'] = df[f'T1-{i}'].rolling(window_size).mean()\n",
    "                df[f'T2-{i}_rolling_mean_{window_size}'] = df[f'T2-{i}'].rolling(window_size).mean()\n",
    "                df[f'V{i}_rolling_mean_{window_size}'] = df[f'V{i}'].rolling(window_size).mean()\n",
    "\n",
    "    # 空间梯度特征\n",
    "    # 假设加热棒之间的空间距离是均匀的\n",
    "    if 'spatial_gradient' in feature_types:\n",
    "        for i in range(1, 17):\n",
    "            df[f'T1-{i}_T1-{i + 1}_gradient'] = (df[f'T1-{i + 1}'] - df[f'T1-{i}']) / i\n",
    "            df[f'T2-{i}_T2-{i + 1}_gradient'] = (df[f'T2-{i + 1}'] - df[f'T2-{i}']) / i\n",
    "\n",
    "    # 时间梯度特征\n",
    "    if 'time_gradient' in feature_types:\n",
    "        for i in range(1, 18):\n",
    "            df[f'T1-{i}_time_gradient'] = df[f'T1-{i}'].diff()\n",
    "            df[f'T2-{i}_time_gradient'] = df[f'T2-{i}'].diff()\n",
    "            df[f'V{i}_time_gradient'] = df[f'V{i}'].diff()\n",
    "\n",
    "    # 时空梯度特征\n",
    "    if 'time_spatial_gradient' in feature_types:\n",
    "        for i in range(1, 17):\n",
    "            df[f'T1-{i}_T1-{i + 1}_time_gradient'] = df[f'T1-{i + 1}'].diff() - df[f'T1-{i}'].diff()\n",
    "            df[f'T2-{i}_T2-{i + 1}_time_gradient'] = df[f'T2-{i + 1}'].diff() - df[f'T2-{i}'].diff()\n",
    "            df[f'V{i}_V{i + 1}_time_gradient'] = df[f'V{i + 1}'].diff() - df[f'V{i}'].diff()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_add = generate_features(df_train.copy(), USE_FEATURE_TYPES)\n",
    "df_add_test = generate_features(df_train.copy(), USE_FEATURE_TYPES)\n",
    "\n",
    "df_add.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练前预处理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_cols = df_add.columns[53: 53 + 17 * 2].tolist()\n",
    "feature_cols = [col for col in df_add.columns if col not in target_cols + ['index', 'datetime', 'timestamp']]\n",
    "# 训练集特征向量\n",
    "X = df_add[feature_cols]\n",
    "\n",
    "# 测试集特征向量\n",
    "X_test = df_add_test[feature_cols]\n",
    "\n",
    "# 训练集标签向量\n",
    "Y = df_add[target_cols]\n",
    "\n",
    "# TODO 压缩内存\n",
    "X.shape, Y.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 超参数优化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial, x, y_target):\n",
    "    \"\"\"\n",
    "    :param trial:\n",
    "    :param x: n维特征向量\n",
    "    :param y_target: 一维标签向量\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # 超参数范围\n",
    "    params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression_l1',\n",
    "            'metric': 'mae',\n",
    "            'min_child_weight': 5,\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "            'lambda_l2': 10,\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "            'seed': 2023,\n",
    "            'nthread': 16,\n",
    "            'verbose': -1,\n",
    "            'device': 'cpu'\n",
    "    }\n",
    "\n",
    "    # 5-Fold 交叉验证\n",
    "    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    mae_scores_target = []  # Store the MAE for each fold\n",
    "\n",
    "    # 使用mae确定最优超参数\n",
    "    for train_index, val_index in kf.split(x):\n",
    "        X_train, X_val = x.iloc[train_index], x.iloc[val_index]\n",
    "        y_train, y_val = y_target.iloc[train_index], y_target.iloc[val_index]\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "        gbm = lgb.train(params, train_data, valid_sets=val_data, num_boost_round=TRAIN_ROUND)\n",
    "\n",
    "        y_val_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "        mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "        mae_scores_target.append(mae)\n",
    "\n",
    "    # Pass the average score back to optuna\n",
    "    average_mae = np.mean(mae_scores_target)\n",
    "    trial.report(average_mae, step=0)\n",
    "\n",
    "    return average_mae\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 多目标训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def sequential_optimization(x, y):\n",
    "    for i, target in enumerate(y.columns):\n",
    "        y_target = y[target]\n",
    "\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "\n",
    "        study.optimize(lambda trial: objective(trial, x, y_target), n_trials=OPTUNA_ROUND)\n",
    "\n",
    "        best_params = study.best_trial.params\n",
    "\n",
    "        # Train and save a model using the best hyperparameters\n",
    "        train_data = lgb.Dataset(x, label=y_target)\n",
    "        gbm_best = lgb.train(best_params, train_data, num_boost_round=TRAIN_ROUND)\n",
    "\n",
    "        dump(gbm_best, f'./models/model_{i}.joblib')\n",
    "\n",
    "        # 可视化\n",
    "        ov.plot_optimization_history(study).show()\n",
    "        ov.plot_param_importances(study).show()\n",
    "\n",
    "\n",
    "# 并行版本\n",
    "def parallel_optimization(x, y, ):\n",
    "    # Optimize the hyperparameters for each target in parallel\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "            delayed(lambda trial: objective(trial, x, y[col]))(optuna.create_study(direction='minimize'), n_trials=OPTUNA_ROUND) for col in\n",
    "            y.columns)\n",
    "\n",
    "    # Get the best hyperparameters for each target\n",
    "    best_params_list = [res.params for res in results]\n",
    "\n",
    "    # Train and save a model for each target using the best hyperparameters\n",
    "    for i, (target, best_params) in enumerate(zip(y.columns, best_params_list)):\n",
    "        train_data = lgb.Dataset(x, label=y[target])\n",
    "        gbm_best = lgb.train(best_params, train_data, num_boost_round=5000)\n",
    "        dump(gbm_best, f'./models/model_parallel_{i}.joblib')\n",
    "        # Visualize the optimization history and parameter importances for each target\n",
    "        # ov.plot_optimization_history(study).show()\n",
    "        # ov.plot_param_importances(study).show()\n",
    "\n",
    "\n",
    "sequential_optimization(X, Y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型推理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_by_multi_targets(x, y):\n",
    "    \"\"\"\n",
    "    使用保存的模型分开预测\n",
    "    :param x: 测试集特征向量\n",
    "    :param y: 训练集标签向量，用于提取名称\n",
    "    \"\"\"\n",
    "    # Initialize an empty dataframe to store the predictions\n",
    "    df_predictions = pd.DataFrame()\n",
    "\n",
    "    # For each target, load the corresponding model and make predictions\n",
    "    for i in range(len(y.columns)):\n",
    "        # Load the model\n",
    "        gbm_best_saved = load(f'model_{i}.joblib')\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = gbm_best_saved.predict(x)\n",
    "\n",
    "        # Store the predictions in the dataframe\n",
    "        df_predictions[f'target_{i}'] = predictions\n",
    "\n",
    "    # Save the predictions to a csv file\n",
    "    df_predictions.to_csv('predictions.csv', index=False)\n",
    "\n",
    "\n",
    "predict_by_multi_targets(X_test, Y)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
